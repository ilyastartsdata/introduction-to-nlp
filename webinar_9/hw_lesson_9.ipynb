{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw_lesson_9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Задание\n",
        "\n",
        "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jt-2n4GaFjAv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa51-w2rEfEt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('evgenyi_onegin.txt','rb').read().decode(encoding = 'utf-8')\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "id": "-0RlxFnCFzTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text + text"
      ],
      "metadata": {
        "id": "yEPLy22IGH_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "metadata": {
        "id": "Ydgd_E1lGIic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text as int\n",
        "\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "metadata": {
        "id": "Q1iso0ZYGOoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "j6Xm7VqfGS-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and target\n",
        "\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "    print(idx2char[i.numpy()])"
      ],
      "metadata": {
        "id": "cVzjK7phGTdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder = True)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "metadata": {
        "id": "6Zc4ZXJDGZVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "amjDAWWNGiCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "metadata": {
        "id": "52odN3CxGkBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HREXNHvvGv0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch and buffer\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
      ],
      "metadata": {
        "id": "qu_dkpvCGwQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 128\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "1wuqwVw-G1sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class RNNgenerator\n",
        "\n",
        "class RNNgenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super(RNNgenerator, self).__init__()\n",
        "        \n",
        "        self.emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "                                 \n",
        "        self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences = True,\n",
        "                            stateful = False,\n",
        "                            recurrent_initializer = 'glorot_uniform')\n",
        "\n",
        "        self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences = True,\n",
        "                            stateful = False,\n",
        "                            recurrent_initializer = 'glorot_uniform')\n",
        "        self.gru3 = tf.keras.layers.GRU(rnn_units,\n",
        "                            return_sequences = True,\n",
        "                            stateful = False,\n",
        "                            recurrent_initializer = 'glorot_uniform')\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, x):\n",
        "        emb_x = self.emb(x)\n",
        "        x = self.gru1(emb_x)\n",
        "        x = self.gru2(x)\n",
        "        x = self.gru3(x)\n",
        "\n",
        "        x = self.dense(x)\n",
        "        return x \n",
        "\n",
        "model = RNNgenerator(vocab_size,\n",
        "                     embedding_dim,\n",
        "                     rnn_units = rnn_units\n",
        "                     )"
      ],
      "metadata": {
        "id": "ZvYqyUQ-G7cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "xDouHXkrHL1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def loss\n",
        "\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
      ],
      "metadata": {
        "id": "d0OyfPHZHMSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam', loss = loss, metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "zSvSYQJ_HTfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoints\n",
        "\n",
        "checkpoint_dir = './RNN_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath = checkpoint_prefix,\n",
        "                                save_freq = 5,\n",
        "                                save_weights_only = True)"
      ],
      "metadata": {
        "id": "Yeu06Wo4HoQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "u6UL4UmiHzHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "EPOCHS = 500\n",
        "history = model.fit(dataset,\n",
        "                    epochs = EPOCHS,\n",
        "                    callbacks = [checkpoint_callback])"
      ],
      "metadata": {
        "id": "25MUPA4oHzjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jlDq3fqaIA_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "id": "5nO4mzbRIEJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "f_w-Ej2ZIG5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNgenerator(vocab_size, embedding_dim, rnn_units)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "zvAYyPnXIHYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "LBXZC43yIMFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text\n",
        "\n",
        "num_generate = 500\n",
        "temperature = 1"
      ],
      "metadata": {
        "id": "Htd1zTLiIMew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        \n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "4zdPignjIQYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ = generate_text(model, start_string = u\"И вот идет уже \")\n",
        "print(text_)"
      ],
      "metadata": {
        "id": "g0pOcQP6IVVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check 200 epoch\n",
        "\n",
        "model = RNNgenerator(vocab_size, embedding_dim, rnn_units) \n",
        "model.load_weights('./RNN_checkpoints/ckpt_200')\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "V96rvw5nIblW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ = generate_text(model, start_string = u\"И вот идет уже \")\n",
        "print(text_)"
      ],
      "metadata": {
        "id": "w6e20i6IIgRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "64jAvak2ImyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNgenerator_1(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.gru3 = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, states=None, return_state=False):\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    if states is None:\n",
        "      states = self.gru1.get_initial_state(x)\n",
        "\n",
        "    x, states = self.gru1(x, initial_state=states)\n",
        "    x, states = self.gru2(x, initial_state=states)\n",
        "    x, states = self.gru3(x, initial_state=states)\n",
        "\n",
        "    x = self.dense(x)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "MUQ4OBe-Ihzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heckpoint_dir = './RNN_checkpoints'\n",
        "\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath = checkpoint_prefix,\n",
        "                                save_freq = 1,\n",
        "                                save_weights_only = True)"
      ],
      "metadata": {
        "id": "MHCOgA2UIp_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = RNNgenerator_1(\n",
        "                 vocab_size = vocab_size,\n",
        "                 embedding_dim = embedding_dim,\n",
        "                 rnn_units = rnn_units,\n",
        "                )"
      ],
      "metadata": {
        "id": "sPATFqflItNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(optimizer = 'adam', loss = loss, metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "qsp8Ee2WIxIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.load_weights('./RNN_checkpoints/ckpt_200')"
      ],
      "metadata": {
        "id": "0jmQ_2WCI0xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "NKisS2VGI42b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text\n",
        "\n",
        "def generate_text_1(model, start_string, states, temperature):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions, states = model(input_eval, states=states, return_state=True)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        \n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "7qxF8TnFI2iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_generate = 500\n",
        "temperature = 0.6\n",
        "states = None\n",
        "next_char = u\"И вот идет уже \"\n",
        "text_generated = []"
      ],
      "metadata": {
        "id": "b_qztWTRI8Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = generate_text_1(model_1, next_char, states, temperature)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "q0uuswqTJAGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "uvbY5_R-JCd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNgenerator_2(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru1 = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.gru2 = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.gru3 = tf.keras.layers.GRU(rnn_units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, states_1=None, states_2=None, states_3=None, return_state=False):\n",
        "\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    if states is None:\n",
        "      states_1 = self.gru1.get_initial_state(x)\n",
        "      states_2 = self.gru1.get_initial_state(x)\n",
        "      states_3 = self.gru1.get_initial_state(x)\n",
        "\n",
        "    x, states_1 = self.gru1(x, initial_state=states_1)\n",
        "    x, states_2 = self.gru2(x, initial_state=states_2)\n",
        "    x, states_3 = self.gru3(x, initial_state=states_3)\n",
        "\n",
        "    x = self.dense(x)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states_1, states_2, states_3\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "PO1f15xPJBMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './RNN_2_checkpoints'\n",
        "checkpoint_dir = './RNN_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                filepath = checkpoint_prefix,\n",
        "                                save_freq = 1,\n",
        "                                save_weights_only = True)"
      ],
      "metadata": {
        "id": "OBA14AgsJEZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = RNNgenerator_2(\n",
        "                 vocab_size = vocab_size,\n",
        "                 embedding_dim = embedding_dim,\n",
        "                 rnn_units = rnn_units,\n",
        "                )"
      ],
      "metadata": {
        "id": "8Dc22s98JI79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(optimizer = 'adam', loss = loss, metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "3NRVE9WvJMFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.load_weights('./RNN_checkpoints/ckpt_200')"
      ],
      "metadata": {
        "id": "cNhSy2wbJRF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_2(model, start_string, states_1, states_2, states_3, temperature):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Here batch size == 1\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions, states_1,states_2, states_3 = model(input_eval, states_1=states_1, states_2=states_2, states_3=states_3, return_state=True)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        \n",
        "        # using a categorical distribution to predict the character returned by the model\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Pass the predicted character as the next input to the model\n",
        "        # along with the previous hidden state\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "KNZQtz8RJT2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_generate = 500\n",
        "temperature = .5\n",
        "states_1 = None\n",
        "states_2 = None\n",
        "states_3 = None\n",
        "next_char = u\"И вот идет уже \"\n",
        "text_generated = []"
      ],
      "metadata": {
        "id": "G2gYXwViJVU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "PIwL25VgJZYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = generate_text_2(model_2, next_char, states_1, states_2, states_3, temperature)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "hzgEy_paJXE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}